# -*- coding: utf-8 -*-
"""PacificSound256kHz.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1i2ROkulVzON1QAOfQWI5wgXVPuAJzX2n

![alt text](https://www.mbari.org/wp-content/uploads/2014/11/logo-mbari-3b.png "MBARI")

  <div align="left">Copyright (c) 2022, MBARI</div>
    
  * Distributed under the terms of the GPL License
  * Maintainer: dcline@mbari.org
  * Authors: Danelle Cline dcline@mbari.org, John Ryan ryjo@mbari.org

## Basic Exploration of the 256 kHz Pacific Ocean Audio Data in the AWS Open Data Registry

---
An extensive (5+ years and growing) archive of sound recordings from a deep-sea location [along the eastern margin of the North Pacific Ocean](https://www.mbari.org/at-sea/cabled-observatory/) has been made available through AWS Open data.  Temporal coverage of the recording archive has been 95% since project inception in July 2015.  The original recordings have a sample rate of 256 kHz.  This notebook illustrates basic methods to access and process the original audio data using Python.

If you use this data set, please **[cite our project](https://ieeexplore.ieee.org/document/7761363).**

 <div style="text-align: center">
 <h3>A delayed version of this data can be heard here on this live audio station</h3>
 <audio controls>
 <source src="http://listen.shoutcast.com/oceansoundscape" type="audio/mpeg">
 Your browser does not support the audio player to play the live stream from Monterey Bay  </audio>
</div>

## Data Overview
The full-resolution audio data are in [WAV](https://en.wikipedia.org/wiki/WAV) format in s3 buckets named <b>pacific-sound-256khz-yyyy</b>, where yyyy is 2015 or later.  Buckets are stored as objects, so the data aren't physically stored in folders or directories as you may be famaliar with, but you can think of it conceptually as follows:

```
pacific-sound-256khz-2021
      |
      individual 10-minute files
```

## Install required dependencies

First, let's install the required software dependencies.

If you are using this notebook in a cloud environment, select a Python3 compatible kernel and run this next section.  This only needs to be done once for the duration of this notebook.

If you are working on local computer, you can skip this next cell. Change your kernel to *pacific-sound-notebooks*, which you installed according to the instructions in the [README](https://github.com/mbari-org/pacific-sound-notebooks/) - this has all the dependencies that are needed.
"""

!pip install -q boto3
!pip install -q soundfile
!pip install -q scipy
!pip install -q numpy
!pip install -q matplotlib

"""### Import all packages"""

import boto3
from botocore import UNSIGNED
from botocore.client import Config
from six.moves.urllib.request import urlopen
import io
import scipy
from scipy import signal, interpolate
import numpy as np
import soundfile as sf
import matplotlib.pyplot as plt
from sys import prefix

"""## List the contents of a monthly directory"""

s3 = boto3.client('s3',
    aws_access_key_id='',
    aws_secret_access_key='',
    config=Config(signature_version=UNSIGNED))

# bucket = 'pacific-sound-256khz-2020'

# paginator = s3.get_paginator('list_objects_v2')
# page_iterator = paginator.paginate(Bucket=bucket)
# i=0

# for page in page_iterator:
#     for obj in page.get('Contents', []):
#         print(obj['Key']
#         i+=1
# print(f'There are {i} objects in the bucket')


# for page in response_iterator:
#     if 'Contents' in page:
#         for obj in page['Contents']:
#             if obj['Key'].endswith(''):
#                 print(obj['Key'])
# bucket = 'pacific-sound-256khz-2020'

# paginator = s3.get_paginator('list_objects_v2')
# page_iterator = paginator.paginate(Bucket=bucket)
# i=0

# for page in page_iterator:
#     for obj in page.get('Contents', []):
#         print(obj['Key']) # Missing closing parenthesis
#         i+=1
# print(f'There are {i} objects in the bucket')


# for page in response_iterator:
#     if 'Contents' in page:
#         for obj in page['Contents']:
#             if obj['Key'].endswith(''):
#                 print(obj['Key'])


bucket ='pacific-sound-256khz-2020'
on_list=[]
# for i in range(215,235216,10)
prefix=f'02/MARS_20200203_00' # Prefix should be a string
for  obj in s3.list_objects_v2(Bucket=bucket,Prefix=prefix)['Contents']:
  print(obj['Key'])
  on_list.append(obj['Key'])

"""## Read metadata from a file"""

# convert scaled voltage to volts

total_sec = 0
target_sec = 3600  # 1 hour
x_all = []

# for samples in key_list:
#   filename = samples
#   url = f'https://{bucket}.s3.amazonaws.com/{filename}'
#   x, sample_rate = sf.read(io.BytesIO(urlopen(url).read()),dtype='float32')
#   v = x*3
#   nsec = (v.size)/sample_rate # number of seconds in vector
#   spa = 1  # seconds per average
#   nseg = int(nsec/spa)
#   print(f'{nseg} segments of length {spa} seconds in {nsec} seconds of audio')



for obj in on_list:

    key = obj
    url = f'https://{bucket}.s3.amazonaws.com/{key}'
    x, sample_rate = sf.read(io.BytesIO(urlopen(url).read()), dtype='float32')
    v1=signal.resample(x*3,600*48000)
    v = v1 * 3  # scale to volts
    dur = len(v) / 48000
    print(total_sec)
    total_sec += dur
    x_all.append(v)

    if total_sec >= target_sec:
        break

sample_rate=48000



v_concat = np.concatenate(x_all)
v_concat = v_concat[:int(sample_rate * target_sec)]

"""## Read data from a file

### Calibrated Spectrum Levels

### Calibration metadata
Frequency-dependent hydrophone sensitivity data are defined in the following files, one for each deployment:
*   https://bitbucket.org/mbari/pacific-sound/src/master/MBARI_MARS_Hydrophone_Deployment01.json
*   https://bitbucket.org/mbari/pacific-sound/src/master/MBARI_MARS_Hydrophone_Deployment02.json

### Compute spectrogram
"""

# initialize empty LTSA

nsec = (v_concat.size)/sample_rate # number of seconds in vector
spa = 1  # seconds per average
nseg = int(nsec/spa)
nfreq = int(sample_rate/2+1)
nfreq,nseg
sg = np.empty((nfreq, nseg), float)
sg.shape
print(nseg)

# get window for welch

w = scipy.signal.get_window('hann',sample_rate)
# print(w.size)
psd_mlog=[]

# process spectrogram
for x in range(0,nseg):
  cstart = x*spa*sample_rate
  cend = (x+1)*spa*sample_rate
  f,psd = scipy.signal.welch(v_concat[cstart:cend],fs=sample_rate,window=w,nfft=sample_rate)
  sg[:,x]=10*np.log10(psd)

# for i in range(0,nfreq):
  # psd_mean = np.mean(psd[i])  # Store psd in the corresponding column of psd_mean
  # psd_mlog.append(10*np.log10(psd_mean)) # Calculate psd_mlog for the current segment
  # sg[i] =10*np.log10(psd_mean)



# psd_mean.shape
# print(psd_mlog)
sg.shape

# print(psd_mean)
# psd_mean.shape

"""### Apply calibration
Frequency-dependent hydrophone sensitivity data are reported in the json files identified above.  This example file is from the second hydrophone deployment, for which the calibration data are manually entered below.  Note that the lowest measured value, at 250 Hz, is assumed to cover lower frequencies and repeated as a value at 0 Hz to allow interpolation to the spectrogram output frequencies across the full frequency range.


"""

# define hydrophone calibration data

calfreq = [0,250,10000,20100,30100,40200,50200,60200,70300,80300,90400,100400,110400,120500,130500,140500,150600,160600,170700,180700,190700,200000]
calsens = [-177.90,-177.90,-176.80,-176.35,-177.05,-177.35,-177.30,-178.05,-178.00,-178.40,-178.85,-180.25,-180.50,-179.90,-180.15,-180.20,-180.75,-180.90,-181.45,-181.30,-180.75,-180.30]

# interpolate to the frequency resolution of the spectrogram
tck = interpolate.splrep(calfreq, calsens, s=0)
isens = interpolate.splev(f, tck, der=0)
plt.figure(dpi=300)
im = plt.plot(calfreq,calsens,'bo',f,isens,'g')
plt.xlabel('Frequency (Hz)')
plt.ylabel('Hydrophone sensitivity (dB re V/uPA)')
plt.legend(['Factory, measured', 'Interpolated'])

# replicate interpolated sensitivity
isensg = np.transpose(np.tile(isens,[nseg,1]))
isensg.shape

test_1k=np.mean((sg-isensg)[1000,:])
test_4k=(sg-isensg)[4000,:]
test_8k=(sg-isensg)[8000,:]
test_12k=(sg-isensg)[12000,:]
test_16k=(sg-isensg)[16000,:]
# print(psd_mlog-isensg)
# print(sg-isensg[1000,:])
print(test_1k)

sg.shape
print(sg)
# np.savetxt(sg-isensg)

data_dict = {'matrix': sg-isensg[1000,:]}

# Save the data to a .mat file
# scipy.io.savemat('calib_MARS_20200203_12.mat', data_dict)

"""### Plot the calibrated spectrogram"""

print(isensg[1000,:])


# time_map = np.linspace(0, 23, nseg,endpoint=False)  # shape = (3600,)

# # Extract 1000th frequency bin from calibrated PSD (shape = (3600,))
# calibrated_psd_at_1000 = sg[1000, :] - isensg[1000, :]

# # Plot
# plt.figure(dpi=300)
# plt.plot(time_map, calibrated_psd_at_1000)
# plt.xlabel('Time (hours)')
# plt.ylabel('Calibrated PSD at ~1000 Hz (dB)')
# plt.title('Calibrated spectrum level at ~1000 Hz over 24 hours')
# plt.grid(True)
# plt.show()